# AI模型配置使用指南

## 概述

小说阅读神器现在支持配置OpenAI兼容的AI大模型，提供更智能的小说内容总结功能。通过配置AI模型，您可以获得比传统规则总结更准确、更智能的内容分析结果。

## 功能特性

- ✅ **多模型支持**：可配置多个不同服务商的AI模型
- ✅ **安全存储**：API密钥本地加密存储，确保信息安全
- ✅ **连接测试**：提供模型连接测试功能，确保配置正确
- ✅ **模板支持**：内置常用AI服务商配置模板
- ✅ **自动降级**：AI模型不可用时自动回退到规则总结
- ✅ **灵活切换**：支持设置和切换默认AI模型

## 支持的AI服务商

### 官方服务商
- **OpenAI**：GPT-3.5、GPT-4等官方模型
- **Azure OpenAI**：微软Azure平台上的OpenAI服务

### 本地部署
- **LocalAI**：本地部署的开源AI服务
- **Ollama**：本地运行的轻量级AI模型服务

### 其他兼容服务
任何兼容OpenAI API格式的AI服务商都可以配置使用。

## 快速开始

### 1. 打开AI配置界面

在小说阅读神器主界面工具栏中，点击 **"⚙️ AI配置"** 按钮，打开AI模型配置对话框。

### 2. 添加AI模型

#### 方法一：使用配置模板（推荐）

1. 在模型详情区域的"配置模板"下拉框中选择合适的模板
2. 系统会自动填充基本的配置信息
3. 根据您的实际情况修改API密钥等信息
4. 点击"测试连接"验证配置是否正确
5. 点击"保存配置"完成添加

#### 方法二：手动配置

1. 在左侧模型列表中点击"➕ 添加模型"
2. 在右侧详情区域填写以下信息：
   - **模型名称**：为这个模型起一个易于识别的名称
   - **API基础URL**：AI服务的API地址
   - **API密钥**：您的API访问密钥
   - **API模型**：要使用的具体模型名称
   - **设为默认模型**：勾选此项将此模型设为默认使用
3. 点击"测试连接"验证配置
4. 点击"保存配置"完成添加

### 3. 使用AI总结功能

配置完成后，您可以：

1. 在浏览器中打开小说章节页面
2. 点击"📄 提取内容"提取小说文本
3. 点击"📝 AI总结"进行智能总结
4. 系统会自动使用您配置的默认AI模型进行总结
5. 如果AI模型不可用，会自动回退到规则总结

## 详细配置说明

### OpenAI配置

**配置模板**：选择"OpenAI"

**配置信息**：
- 模型名称：`OpenAI ChatGPT`（可自定义）
- API基础URL：`https://api.openai.com/v1`
- API模型：`gpt-3.5-turbo` 或 `gpt-4`
- API密钥：您的OpenAI API密钥（以`sk-`开头）

**获取API密钥**：
1. 访问 [OpenAI官网](https://platform.openai.com/)
2. 注册并登录账户
3. 进入API密钥管理页面
4. 创建新的API密钥

### Azure OpenAI配置

**配置模板**：选择"Azure OpenAI"

**配置信息**：
- 模型名称：`Azure OpenAI`（可自定义）
- API基础URL：`https://your-resource-name.openai.azure.com/`
- API模型：`gpt-35-turbo`（根据您的部署名称）
- API密钥：您的Azure API密钥

**注意事项**：
- 需要将`your-resource-name`替换为您的Azure资源名称
- 模型名称需要与您在Azure中部署的模型名称一致

### LocalAI配置

**配置模板**：选择"LocalAI"

**配置信息**：
- 模型名称：`LocalAI`（可自定义）
- API基础URL：`http://localhost:8080/v1`
- API模型：根据您下载的模型而定
- API密钥：可以为空（本地部署通常不需要）

**前提条件**：
1. 已在本地部署LocalAI服务
2. LocalAI服务运行在8080端口
3. 已下载相应的AI模型

### Ollama配置

**配置模板**：选择"Ollama"

**配置信息**：
- 模型名称：`Ollama`（可自定义）
- API基础URL：`http://localhost:11434/v1`
- API模型：如`llama2`、`codellama`等
- API密钥：可以为空（本地部署通常不需要）

**前提条件**：
1. 已安装Ollama
2. Ollama服务运行在11434端口
3. 已拉取相应的AI模型

## 配置管理

### 编辑模型

1. 在左侧模型列表中选择要编辑的模型
2. 右侧详情区域会显示当前配置
3. 修改需要更改的信息
4. 点击"保存配置"完成编辑

### 删除模型

1. 在左侧模型列表中选择要删除的模型
2. 点击"🗑️ 删除"按钮
3. 确认删除操作

### 切换默认模型

1. 在左侧模型列表中选择要设为默认的模型
2. 点击"⭐ 设为默认"按钮
3. 该模型将被标记为默认模型

### 测试连接

1. 完成模型配置后，点击"🔗 测试连接"按钮
2. 系统会尝试连接到AI服务并验证配置
3. 测试结果会显示在下方的测试结果区域
4. 连接成功表示配置正确，可以正常使用

## 故障排除

### 常见问题

**Q1: 测试连接失败怎么办？**

**A**: 请检查以下几点：
- API密钥是否正确输入
- API基础URL是否正确
- 网络连接是否正常
- AI服务是否正常运行（本地部署时）
- 账户是否有足够的配额

**Q2: AI总结功能没有使用我配置的模型？**

**A**: 请确认：
- 您已将模型设为默认模型
- 模型配置已成功保存
- 测试连接显示成功

**Q3: 为什么会自动使用规则总结？**

**A**: 可能的原因：
- 没有配置默认AI模型
- AI模型连接失败
- API调用出现错误
- 没有配置AI模型

**Q4: API密钥安全吗？**

**A**: 请放心：
- API密钥使用本地加密存储
- 不会上传到任何云端服务器
- 配置文件已添加到.gitignore，不会被提交到代码仓库

**Q5: 支持哪些AI模型？**

**A**: 支持所有兼容OpenAI API格式的模型：
- OpenAI官方模型（GPT-3.5、GPT-4等）
- Azure OpenAI模型
- 本地部署的开源模型
- 第三方兼容服务

### 错误代码说明

- **HTTP 401/403**：认证失败，请检查API密钥
- **HTTP 429**：请求频率过高，请稍后重试
- **HTTP 500+**：服务器错误，可能是服务商问题
- **TIMEOUT**：请求超时，请检查网络连接
- **CONNECTION_ERROR**：连接失败，请检查URL和网络

## 高级用法

### 多模型配置

您可以配置多个AI模型用于不同场景：
- **快速总结**：使用快速的轻量级模型
- **深度分析**：使用功能强大的大型模型
- **备用模型**：在主模型不可用时自动切换

### 成本优化

- 选择合适的模型规模
- 设置合理的token限制
- 监控API使用情况
- 使用本地模型节省费用

### 性能优化

- 选择地理位置较近的服务
- 使用HTTP连接池
- 设置合适的超时时间
- 启用响应缓存

## 安全建议

1. **保护API密钥**：
   - 不要分享API密钥
   - 定期更换密钥
   - 使用最小权限原则

2. **网络安全**：
   - 使用HTTPS连接
   - 验证SSL证书
   - 避免使用公共网络

3. **数据隐私**：
   - 了解服务商的隐私政策
   - 避免发送敏感信息
   - 定期清理使用记录

## 更新日志

### v2.0 (2025-11-25)
- ✨ 新增AI模型配置功能
- ✨ 支持多种AI服务商
- ✨ 新增配置模板功能
- ✨ 实现API密钥加密存储
- ✨ 添加连接测试功能
- ✨ 支持自动降级机制

## 技术支持

如果您在使用过程中遇到问题：

1. 查看本文档的故障排除部分
2. 检查项目GitHub仓库的Issues
3. 提交新的Issue描述您的问题
4. 联系开发团队获取帮助

---

**文档版本**: 1.0  
**最后更新**: 2025-11-25  
**适用于**: 小说阅读神器 v2.0+
