#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´é˜…è¯»ç¥å™¨ - AIæ€»ç»“æ¨¡å—
æä¾›å¤šç§æ–¹å¼å¯¹æ–‡æœ¬è¿›è¡Œæ™ºèƒ½æ€»ç»“
"""

import re
import math
import jieba
import jieba.analyse
from collections import defaultdict

class TextSummarizer:
    """æ–‡æœ¬æ€»ç»“ç±»ï¼Œæä¾›å¤šç§æ€»ç»“æ–¹æ³•"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        # åŠ è½½jiebaè‡ªå®šä¹‰è¯å…¸
        try:
            jieba.load_userdict("novel_dict.txt")
        except:
            print("æœªæ‰¾åˆ°è‡ªå®šä¹‰è¯å…¸")
    
    def extract_keywords(self, text, topK=10):
        """æå–å…³é”®è¯"""
        keywords = jieba.analyse.extract_tags(text, topK=topK, withWeight=True)
        return keywords
    
    def get_important_sentences(self, text, topK=3):
        """è·å–æœ€é‡è¦çš„å‡ ä¸ªå¥å­"""
        # åˆ†å¥
        text = re.sub(r'([ã€‚ï¼ï¼Ÿ\?])([^"'])', r'\1\n\2', text)
        text = re.sub(r'(\.{6})([^"'])', r'\1\n\2', text)
        text = re.sub(r'(\â€¦{2})([^"'])', r'\1\n\2', text)
        text = re.sub(r'([ã€‚ï¼ï¼Ÿ\?]["'])([^ï¼Œã€‚ï¼ï¼Ÿ\?])', r'\1\n\2', text)
        
        sentences = text.split('\n')
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if len(sentences) <= topK:
            return sentences
        
        # æå–å…³é”®è¯
        keywords_dict = {}
        keywords = self.extract_keywords(text, topK=20)
        for word, weight in keywords:
            keywords_dict[word] = weight
        
        # è®¡ç®—å¥å­å¾—åˆ†
        sentence_scores = []
        for i, sentence in enumerate(sentences):
            score = 0
            for word in jieba.cut(sentence):
                if word in keywords_dict:
                    score += keywords_dict[word]
            
            # è€ƒè™‘å¥å­ä½ç½®å› ç´ 
            # å¼€å¤´å’Œç»“å°¾çš„å¥å­æƒé‡ç•¥é«˜
            position_weight = 1.0
            if i < len(sentences) * 0.1 or i > len(sentences) * 0.9:
                position_weight = 1.2
            
            score = score * position_weight
            sentence_scores.append((i, sentence, score))
        
        # æŒ‰å¾—åˆ†æ’åº
        sentence_scores.sort(key=lambda x: x[2], reverse=True)
        
        # å–å‡ºå¾—åˆ†æœ€é«˜çš„topKä¸ªå¥å­ï¼Œå¹¶æŒ‰åŸæ–‡é¡ºåºæ’åˆ—
        top_sentences = sentence_scores[:topK]
        top_sentences.sort(key=lambda x: x[0])
        
        return [s[1] for s in top_sentences]
    
    def summarize(self, text, max_ratio=0.3, max_sentences=5):
        """æ€»ç»“æ–‡æœ¬"""
        # 1. æ–‡æœ¬é¢„å¤„ç†
        text = text.replace("\n\n", "\n").strip()
        
        # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥è¿”å›
        if len(text) < 200:
            return {"summary": text, "keywords": [], "ratio": 1.0}
        
        # 2. æå–å…³é”®è¯
        keywords = self.extract_keywords(text, topK=8)
        keyword_list = [word for word, _ in keywords]
        
        # 3. æå–é‡è¦å¥å­
        max_num_sentences = min(max_sentences, int(len(text) / 100))
        if max_num_sentences < 3:
            max_num_sentences = 3
            
        important_sentences = self.get_important_sentences(text, topK=max_num_sentences)
        
        # 4. ç”Ÿæˆæ€»ç»“
        summary = "ã€å†…å®¹æ¦‚è¦ã€‘\n\n"
        summary += "â—† å…³é”®è¯ï¼š" + "ã€".join(keyword_list) + "\n\n"
        summary += "â—† é‡è¦å†…å®¹ï¼š\n"
        summary += "\n".join(["Â· " + s for s in important_sentences])
        summary += "\n\n"
        
        # è®¡ç®—å‹ç¼©æ¯”
        ratio = len(summary) / len(text)
        summary_info = {
            "summary": summary,
            "keywords": keyword_list,
            "important_sentences": important_sentences,
            "ratio": ratio
        }
        
        return summary_info

    def chapter_analysis(self, chapter_text, chapter_title=""):
        """åˆ†æå°è¯´ç« èŠ‚"""
        # æ£€æµ‹ç« èŠ‚æ ‡é¢˜
        if not chapter_title and len(chapter_text) > 0:
            # å°è¯•ä»æ–‡æœ¬å¼€å¤´æå–ç« èŠ‚æ ‡é¢˜
            first_line = chapter_text.split('\n')[0].strip()
            if len(first_line) < 30 and ('ç« ' in first_line or 'èŠ‚' in first_line):
                chapter_title = first_line
        
        # åŸºæœ¬ç»Ÿè®¡
        char_count = len(chapter_text)
        
        # æ€»ç»“æ–‡æœ¬
        summary_info = self.summarize(chapter_text)
        
        # ç»„è£…ç»“æœ
        result = {
            "title": chapter_title,
            "char_count": char_count,
            "word_count": char_count // 2,  # æ±‰å­—è¿‘ä¼¼è®¡ç®—
            "summary": summary_info["summary"],
            "keywords": summary_info["keywords"],
            "compression_ratio": summary_info["ratio"]
        }
        
        return result
        
    def format_chapter_summary(self, chapter_analysis):
        """æ ¼å¼åŒ–ç« èŠ‚æ€»ç»“ä¸ºæ˜“è¯»çš„å½¢å¼"""
        result = []
        
        # æ·»åŠ æ ‡é¢˜
        if chapter_analysis["title"]:
            result.append(f"# {chapter_analysis['title']}")
        else:
            result.append("# ç« èŠ‚æ¦‚è¦")
            
        result.append("")
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        result.append(f"ğŸ“Š å­—æ•°ç»Ÿè®¡ï¼šçº¦ {chapter_analysis['char_count']} å­—")
        result.append(f"â±ï¸ é˜…è¯»æ—¶é—´ï¼šçº¦ {math.ceil(chapter_analysis['char_count'] / 500)} åˆ†é’Ÿ")
        result.append("")
        
        # æ·»åŠ æ€»ç»“å†…å®¹
        result.append(chapter_analysis["summary"])
        
        return "\n".join(result)

if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    sample_text = """
    å¼ æ— å¿Œè‡ªä»å­¦ä¼šäº†ä¹¾å¤å¤§æŒªç§»å’Œå¤ªææ‹³ï¼Œæ­¦åŠŸå¤§è¿›ï¼Œç°åœ¨ç»ˆäºå¯ä»¥ä¸ºçˆ¶æ¯æŠ¥ä»‡äº†ã€‚
    ä»–æ¥åˆ°äº†å…‰æ˜é¡¶ï¼Œçœ‹åˆ°äº†é˜³é¡¶å¤©ç•™ä¸‹çš„ä¸ƒä¸ªå­—"å…‰æ˜æ­£å¤§ï¼Œæ´—åˆ·æ±¡å¢"ï¼Œå¿ƒä¸­æ„Ÿæ…¨ä¸‡åƒã€‚
    è¿™æ—¶ï¼Œèµµæ•å¸¦ç€ä¸€ç¾¤è’™å¤å…µé—¯äº†è¿›æ¥ï¼Œå¼ æ— å¿Œç«‹å³è¿ä¸Šå‰å»ï¼ŒäºŒäººæˆ˜åœ¨ä¸€å¤„ã€‚
    èµµæ•å‡ºæ‹›ç‹ è¾£ï¼Œå¼ æ— å¿Œåˆ™æ‹›æ‹›ç›¸è®©ï¼Œä¸æ„¿ä¼¤å¥¹ã€‚
    æˆ˜äº†å‡ åæ‹›ï¼Œå¼ æ— å¿Œä»¥ä¹¾å¤å¤§æŒªç§»åŒ–è§£äº†èµµæ•çš„æ‹›å¼ï¼Œå¹¶ç‚¹ä¸­äº†å¥¹çš„ç©´é“ã€‚
    "å¼ æ•™ä¸»ï¼Œä½ ä¸ºä½•ä¸æ€æˆ‘ï¼Ÿ"èµµæ•é—®é“ã€‚
    å¼ æ— å¿Œå¹äº†å£æ°”ï¼š"æˆ‘ä¸å§‘å¨˜æ— å†¤æ— ä»‡ï¼Œåˆæ€ä¼šå–ä½ æ€§å‘½ï¼Ÿ"
    èµµæ•å¿ƒä¸­æ„ŸåŠ¨ï¼Œä»æ­¤å¯¹å¼ æ— å¿ŒèŠ³å¿ƒæš—è®¸ã€‚
    """
    
    summarizer = TextSummarizer()
    analysis = summarizer.chapter_analysis(sample_text, "ç¬¬äºŒåç«  å…‰æ˜é¡¶ä¹‹æˆ˜")
    print(summarizer.format_chapter_summary(analysis))